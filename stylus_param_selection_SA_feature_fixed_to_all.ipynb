{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from random import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_params(param_dict, curr_params=None):\n",
    "    \"\"\"\n",
    "    Function to choose parameters for next iteration\n",
    "    Inputs:\n",
    "    param_dict - Ordered dictionary of hyperparameter search space\n",
    "    curr_params - Dict of current hyperparameters\n",
    "    Output:\n",
    "    Dictionary of parameters\n",
    "    \"\"\"\n",
    "    if curr_params:\n",
    "        next_params = curr_params.copy()\n",
    "        param_to_update = np.random.choice(list(param_dict.keys()))\n",
    "        param_vals = param_dict[param_to_update]\n",
    "        curr_index = param_vals.index(curr_params[param_to_update])\n",
    "        if curr_index == 0:\n",
    "            next_params[param_to_update] = param_vals[1]\n",
    "        elif curr_index == len(param_vals) - 1:\n",
    "            next_params[param_to_update] = param_vals[curr_index - 1]\n",
    "        else:\n",
    "            next_params[param_to_update] = \\\n",
    "                param_vals[curr_index + np.random.choice([-1, 1])]\n",
    "    else:\n",
    "        next_params = dict()\n",
    "        for k, v in param_dict.items():\n",
    "            next_params[k] = np.random.choice(v)\n",
    "\n",
    "    return next_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_annealing(param_dict,\n",
    "                       const_param,\n",
    "                       X_train,\n",
    "                       X_valid,\n",
    "                       Y_train,\n",
    "                       Y_valid,\n",
    "                       fn_train,\n",
    "                       maxiters=100,\n",
    "                       alpha=0.85,\n",
    "                       beta=1.3,\n",
    "                       T_0=0.40,\n",
    "                       update_iters=5):\n",
    "    \"\"\"\n",
    "    Function to perform hyperparameter search using simulated annealing\n",
    "    Inputs:\n",
    "    param_dict - Ordered dictionary of Hyperparameter search space\n",
    "    const_param - Static parameters of the model\n",
    "    Xtrain - Train Data\n",
    "    Xvalid - Validation Data\n",
    "    Ytrain - Train labels\n",
    "    Yvalid - Validaion labels\n",
    "    fn_train - Function to train the model\n",
    "        (Should return model and metric value as tuple, sample commented above)\n",
    "    maxiters - Number of iterations to perform the parameter search\n",
    "    alpha - factor to reduce temperature\n",
    "    beta - constant in probability estimate\n",
    "    T_0 - Initial temperature\n",
    "    update_iters - # of iterations required to update temperature\n",
    "    Output:\n",
    "    Dataframe of the parameters explored and corresponding model performance\n",
    "    \"\"\"\n",
    "    columns = [*param_dict.keys()] + ['Metric', 'Best Metric']\n",
    "    results = pd.DataFrame(index=range(maxiters), columns=columns)\n",
    "    best_metric = -1.\n",
    "    prev_metric = -1.\n",
    "    prev_params = None\n",
    "    best_params = dict()\n",
    "    weights = list(map(lambda x: 10**x, list(range(len(param_dict)))))\n",
    "    hash_values = set()\n",
    "    T = T_0\n",
    "\n",
    "    for i in range(maxiters):\n",
    "        print('Starting Iteration {}'.format(i))\n",
    "        while True:\n",
    "            curr_params = choose_params(param_dict, prev_params)\n",
    "            indices = [param_dict[k].index(v) for k, v in curr_params.items()]\n",
    "            hash_val = sum([i * j for (i, j) in zip(weights, indices)])\n",
    "            if hash_val in hash_values:\n",
    "                print('Combination revisited')\n",
    "            else:\n",
    "                hash_values.add(hash_val)\n",
    "                break\n",
    "\n",
    "        model, metric = fn_train(curr_params, const_param, X_train,\n",
    "                                 X_valid, Y_train, Y_valid)\n",
    "\n",
    "        if metric > prev_metric:\n",
    "            print('Local Improvement in metric from {:8.4f} to {:8.4f} '\n",
    "                  .format(prev_metric, metric) + ' - parameters accepted')\n",
    "            prev_params = curr_params.copy()\n",
    "            prev_metric = metric\n",
    "\n",
    "            if metric > best_metric:\n",
    "                print('Global improvement in metric from {:8.4f} to {:8.4f} '\n",
    "                      .format(best_metric, metric) +\n",
    "                      ' - best parameters updated')\n",
    "                best_metric = metric\n",
    "                best_params = curr_params.copy()\n",
    "                best_model = model\n",
    "        else:\n",
    "            rnd = np.random.uniform()\n",
    "            diff = metric - prev_metric\n",
    "            threshold = np.exp(beta * diff / T)\n",
    "            if rnd < threshold:\n",
    "                print('No Improvement but parameters accepted. Metric change' +\n",
    "                      ': {:8.4f} threshold: {:6.4f} random number: {:6.4f}'\n",
    "                      .format(diff, threshold, rnd))\n",
    "                prev_metric = metric\n",
    "                prev_params = curr_params\n",
    "            else:\n",
    "                print('No Improvement and parameters rejected. Metric change' +\n",
    "                      ': {:8.4f} threshold: {:6.4f} random number: {:6.4f}'\n",
    "                      .format(diff, threshold, rnd))\n",
    "\n",
    "        results.loc[i, list(curr_params.keys())] = list(curr_params.values())\n",
    "        results.loc[i, 'Metric'] = metric\n",
    "        results.loc[i, 'Best Metric'] = best_metric\n",
    "\n",
    "        if i % update_iters == 0:\n",
    "            T = alpha * T\n",
    "\n",
    "    return results, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from random import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
